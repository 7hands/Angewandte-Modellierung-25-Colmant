\documentclass[a4paper,12pt]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[german]{babel}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amsmath,amsfonts,amsthm,bm,graphicx}
\usepackage{tikz,pgfplots}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage{rotating}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{svg}

\title{Aufgabenblatt 11}

\begin{document}
\author{Colmant}
\maketitle
\newpage
\section*{Aufgabe 1: AI infrastructure}


\section*{Aufgabe 2: Justice explained by AI}
In dieser Aufgabe sollten wir einen AI-Agenten simulieren durch dei Fähigkeit von modernen LLM-AIs die Kontext und Kohärenz über mehrere Fragen hinweg beibehalten. Ich habe mir den Aufgaben Teil A vorgenommen, in dem ich eine Conservation zwischen einem AI-Experten und einem Alien simuliere durch gezieltes Prompting. Der AI-Experte soll dem Alien erklären, was Gerechtigkeit ist. Ich habe mich dazu entschieden die AI einen Philosophen spielen zu lassen. Dann habe ich die Argumente so gut wie ich konnte mit meinem Philosophie-Wissen versucht zu zerlegen. Das Ergebnis ist eine interessante Diskussion, die zeigt, wie komplex und vielschichtig das Thema Gerechtigkeit ist und wie wichtig es ist in Definitionen genau und präzise zu sein. Das Gespräch kann unter follgenden Link nach gelesen werden: \href{https://g.co/gemini/share/98469b7d8c1a}{AI conversation}.
\subsection*{Evaluation}
Mir ist gleich zu beginn aufgefallen, dass die AI eine sehr ungewöhnliche Definition von Gerechtigkeit gegeben hat. In ihrem versuch Gerechtigkeit einem ALien ohne gesellschaftlichen Vorwissen zu erklären war die Definition sehr abstrakt und eher unpräzise und lies viel Raum für Missinterpretationen. Fast bis zum Ende hat die AI aber Kohärenz bewahrt und hat den Character des Philosophen nicht gebrochen. Was ich aber schade fand ist dass, die AI nicht wirklich einen Philosophen gespielt, sondern eher alle Philosophischen Ideen wieder gegeben hat. Das führte dazu dass der Character keine wirklichen eigenen Ideen bzw. Feste standpunkte hatte. Das führte dazu dass, die AI die Einwände des Aliens so entkräftet hat indem es einfach eine reihe neuer Argumente gebracht hat, aus dennen sich dann eins ausgesucht werden konnte. Als das Alien dann am Ende zu erkennen gab dass, es die Argumente auf eine eher unmoralische Weise interpretiert brach die AI dann aber doch etwas aus dem Character und es wirkt so als würde eher ein teil des Gedanken Process in der Ausgabe sichtbar sein. In der aller letzten Antwort stimmte die AI dann auch noch dem Alien zu dass, die AI eigentlich gar nicht Gerechtigkeit definieren darf aufgrund der oben genannten Argumente. Für eine Philosophische Diskussion ist die AI unbrauchbar sie ist sowohl zu ungenau und gleichzeitig gibt sie zu viele Argumente auf einmal so dass es sehr schwer ist von einem Argument zum nächsten zu kommen. Das Kann natürlich auch an meinem prompting liegen.


\section*{\href{https://github.com/7hands/Angewandte-Modellierung-25-Colmant}{Github}}
Wie immer sind alle meine benutzten Dateien auf meinem Github zu finden. 
\end{document}
