{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text mining: compare two books\n",
    "# Packages\n",
    "\n",
    "### Install packages\n",
    "\n",
    "\"codecs\" is for reading the text files, \"re\" (regular expretions) and \"collections\" for working with tokens, and \"nltk\" (natural language toolkit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text\n",
    "## comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from scipy) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\svetlanameissner\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install nltk\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download stopwords\n",
    "\n",
    "### Some specialized functions from NLTK\n",
    "You can also download everything in NLTK with nltk.download(), but it will take time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SvetlanaMeissner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the stopwords package from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with codecs.open('SenseSensibility.txt', \"r\", encoding=\"utf-8\") as f:\n",
    "    text_SS = f.read()\n",
    "with codecs.open('EmailsHC2015_part2.txt', \"r\", encoding=\"utf-8\") as f:\n",
    "    text_HC = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data\n",
    "Check for stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "esw = stopwords.words('english')\n",
    "esw.append(\"would\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter tokens (using regular expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_pattern = re.compile('^\\w+$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a token counter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_counter(text):\n",
    "    tokens = WordPunctTokenizer().tokenize(PorterStemmer().stem(text))\n",
    "    tokens = list(map(lambda x: x.lower(), tokens))\n",
    "    tokens = filter(lambda x: x.isalpha(), tokens) # remove numbers\n",
    "    tokens = [token for token in tokens if re.match(word_pattern, token) and token not in esw]\n",
    "    return collections.Counter(tokens), len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to calculate the absolute frequency of the most commen words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(counter, size):\n",
    "    abs_freq = np.array([el[1] for el in counter])\n",
    "    rel_freq = abs_freq / size\n",
    "    index = [el[0] for el in counter]\n",
    "    df = pd.DataFrame(data=np.array([abs_freq, rel_freq]).T, index=index, columns=[\"Absolute frequency\", \"Relative frequency\"])\n",
    "    df.index.name = \"Most common words\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Analyze individual texts\n",
    "\n",
    "Calculate the most common words of Sense and Sensibility and display the 15 most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss_counter, ss_size = get_text_counter(text_SS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most common words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elinor</th>\n",
       "      <td>685.0</td>\n",
       "      <td>0.012813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>578.0</td>\n",
       "      <td>0.010811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marianne</th>\n",
       "      <td>566.0</td>\n",
       "      <td>0.010587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <td>530.0</td>\n",
       "      <td>0.009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>397.0</td>\n",
       "      <td>0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every</th>\n",
       "      <td>376.0</td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>331.0</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>290.0</td>\n",
       "      <td>0.005424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>must</th>\n",
       "      <td>283.0</td>\n",
       "      <td>0.005293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sister</th>\n",
       "      <td>282.0</td>\n",
       "      <td>0.005275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edward</th>\n",
       "      <td>263.0</td>\n",
       "      <td>0.004919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>259.0</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dashwood</th>\n",
       "      <td>252.0</td>\n",
       "      <td>0.004714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>240.0</td>\n",
       "      <td>0.004489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>239.0</td>\n",
       "      <td>0.004470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Absolute frequency  Relative frequency\n",
       "Most common words                                        \n",
       "elinor                          685.0            0.012813\n",
       "could                           578.0            0.010811\n",
       "marianne                        566.0            0.010587\n",
       "mrs                             530.0            0.009914\n",
       "said                            397.0            0.007426\n",
       "every                           376.0            0.007033\n",
       "one                             331.0            0.006191\n",
       "much                            290.0            0.005424\n",
       "must                            283.0            0.005293\n",
       "sister                          282.0            0.005275\n",
       "edward                          263.0            0.004919\n",
       "mother                          259.0            0.004845\n",
       "dashwood                        252.0            0.004714\n",
       "well                            240.0            0.004489\n",
       "time                            239.0            0.004470"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_df(ss_counter.most_common(15), ss_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the 1000 most common words of Sense and Sensibility to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss_df = make_df(ss_counter.most_common(1000), ss_size)\n",
    "ss_df.to_csv(\"SS2_1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the most common words in Hillary Clinton emails and display the 15 most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hc_counter, hc_size = get_text_counter(text_HC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most common words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>8329.0</td>\n",
       "      <td>0.025936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>6272.0</td>\n",
       "      <td>0.019531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>4507.0</td>\n",
       "      <td>0.014035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>4140.0</td>\n",
       "      <td>0.012892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department</th>\n",
       "      <td>4041.0</td>\n",
       "      <td>0.012584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>3858.0</td>\n",
       "      <td>0.012014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gov</th>\n",
       "      <td>3857.0</td>\n",
       "      <td>0.012011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>3812.0</td>\n",
       "      <td>0.011871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <td>3799.0</td>\n",
       "      <td>0.011830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unclassified</th>\n",
       "      <td>3761.0</td>\n",
       "      <td>0.011712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>3006.0</td>\n",
       "      <td>0.009361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <td>2836.0</td>\n",
       "      <td>0.008831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release</th>\n",
       "      <td>2488.0</td>\n",
       "      <td>0.007748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>2190.0</td>\n",
       "      <td>0.006820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.006293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Absolute frequency  Relative frequency\n",
       "Most common words                                        \n",
       "state                          8329.0            0.025936\n",
       "f                              6272.0            0.019531\n",
       "u                              4507.0            0.014035\n",
       "h                              4140.0            0.012892\n",
       "department                     4041.0            0.012584\n",
       "case                           3858.0            0.012014\n",
       "gov                            3857.0            0.012011\n",
       "date                           3812.0            0.011871\n",
       "doc                            3799.0            0.011830\n",
       "unclassified                   3761.0            0.011712\n",
       "sent                           3006.0            0.009361\n",
       "subject                        2836.0            0.008831\n",
       "release                        2488.0            0.007748\n",
       "com                            2190.0            0.006820\n",
       "pm                             2021.0            0.006293"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_df(hc_counter.most_common(15), hc_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the 1000 most common words of Email to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hc_df = make_df(hc_counter.most_common(1000), hc_size)\n",
    "hc_df.to_csv(\"HC2_1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare texts\n",
    "\n",
    "Find the most common words across the two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_counter = ss_counter + hc_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_df = make_df(hc_counter.most_common(1000), 1)\n",
    "most_common_words = all_df.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame with the differences in word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for word in most_common_words:\n",
    "    ss_c = ss_counter.get(word, 0) / ss_size\n",
    "    hc_c = hc_counter.get(word, 0) / hc_size\n",
    "    d = abs(ss_c - hc_c)\n",
    "    df_data.append([ss_c, hc_c, d])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_df = pd.DataFrame(data=df_data, index=most_common_words,\n",
    "                          columns=[\"SS relative frequency\", \"HC relative frequency\", \"Differences in relative frequency\"])\n",
    "dist_df.index.name = \"Most common words\"\n",
    "dist_df.sort_values(\"Differences in relative frequency\", ascending=False, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the most 20 distinctive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SS relative frequency</th>\n",
       "      <th>HC relative frequency</th>\n",
       "      <th>Differences in relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most common words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.025936</td>\n",
       "      <td>0.025450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.019475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.014035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.012892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.012584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gov</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012011</td>\n",
       "      <td>0.012011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.011852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>0.011830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unclassified</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.011712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.011340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <td>0.009914</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.009242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.008968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.007673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.007559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.006820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every</th>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.006585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.006293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clintonemail</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>must</th>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.004649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SS relative frequency  HC relative frequency  \\\n",
       "Most common words                                                 \n",
       "state                           0.000486               0.025936   \n",
       "f                               0.000056               0.019531   \n",
       "u                               0.000000               0.014035   \n",
       "h                               0.000000               0.012892   \n",
       "department                      0.000000               0.012584   \n",
       "gov                             0.000000               0.012011   \n",
       "date                            0.000019               0.011871   \n",
       "doc                             0.000000               0.011830   \n",
       "unclassified                    0.000000               0.011712   \n",
       "case                            0.000673               0.012014   \n",
       "mrs                             0.009914               0.000181   \n",
       "could                           0.010811               0.001569   \n",
       "sent                            0.000393               0.009361   \n",
       "release                         0.000075               0.007748   \n",
       "subject                         0.001272               0.008831   \n",
       "com                             0.000000               0.006820   \n",
       "every                           0.007033               0.000448   \n",
       "pm                              0.000000               0.006293   \n",
       "clintonemail                    0.000000               0.005225   \n",
       "must                            0.005293               0.000645   \n",
       "\n",
       "                   Differences in relative frequency  \n",
       "Most common words                                     \n",
       "state                                       0.025450  \n",
       "f                                           0.019475  \n",
       "u                                           0.014035  \n",
       "h                                           0.012892  \n",
       "department                                  0.012584  \n",
       "gov                                         0.012011  \n",
       "date                                        0.011852  \n",
       "doc                                         0.011830  \n",
       "unclassified                                0.011712  \n",
       "case                                        0.011340  \n",
       "mrs                                         0.009733  \n",
       "could                                       0.009242  \n",
       "sent                                        0.008968  \n",
       "release                                     0.007673  \n",
       "subject                                     0.007559  \n",
       "com                                         0.006820  \n",
       "every                                       0.006585  \n",
       "pm                                          0.006293  \n",
       "clintonemail                                0.005225  \n",
       "must                                        0.004649  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the full list of distinctive words to a dist_SSHC.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_df.to_csv(\"dist_SSHC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
